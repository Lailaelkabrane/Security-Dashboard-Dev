# -*- coding: utf-8 -*-
"""Model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nYOQsocYmz2Hnb5KmqJDcdihQ2bMFrPl
"""

"""
cybersecurity_ids.py
Option B + Feature Set A (Light & Interpretable)
- Stage 1: Binary (BENIGN vs ATTACK)
- Stage 2: Multiclass (DDoS, Malware, BruteForce, WebAttack, PortScan, Botnet)
- Features chosen: numeric flow stats, engineered features
"""

import os, warnings
warnings.filterwarnings("ignore")
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import RobustScaler, LabelEncoder
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix
import joblib

# -------------------------
# CONFIG
# -------------------------
CSV_PATH = "cic_ids2017_cleaned.csv"
MODELS_DIR = "Models"
RANDOM_STATE = 42
SAMPLE_FOR_DEV = True
SAMPLE_SIZE = 100000

os.makedirs(MODELS_DIR, exist_ok=True)

# -------------------------
# Load Data
# -------------------------
df = pd.read_csv(CSV_PATH, parse_dates=['timestamp'], infer_datetime_format=True)
print("Rows loaded:", len(df))

# Optional sample for dev
if SAMPLE_FOR_DEV:
    df = df.sample(n=min(SAMPLE_SIZE, len(df)), random_state=RANDOM_STATE).reset_index(drop=True)
    print("Sampled rows:", len(df))

# -------------------------
# Select Features (Light & Interpretable)
# -------------------------
features = [
    'Flow Duration',
    'Total Fwd Packets',
    'Total Backward Packets',
    'Total Length of Fwd Packets',
    'Total Length of Bwd Packets',
    'Flow Bytes/s',
    'Flow Packets/s',
    'Fwd IAT Mean',
    'Bwd IAT Mean'
]

# Clean inf / NaN
df[features] = df[features].replace([np.inf, -np.inf], np.nan)
df = df.dropna(subset=features)

# Add engineered features
df['ratio_fwd_bwd_pkts'] = (df['Total Fwd Packets'] / df['Total Backward Packets'].replace({0: np.nan})).fillna(0)
df['bytes_per_fwd_pkt'] = (df['Total Length of Fwd Packets'] / df['Total Fwd Packets'].replace({0: np.nan})).fillna(0)
features += ['ratio_fwd_bwd_pkts', 'bytes_per_fwd_pkt']

print("Final features:", features)

# -------------------------
# Stage 1: Binary classifier
# -------------------------
df_stage1 = df.copy()
df_stage1['is_attack_binary'] = (df_stage1['attack_type'] != 'BENIGN').astype(int)

X = df_stage1[features].astype(float)
y = df_stage1['is_attack_binary'].values

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=RANDOM_STATE)
print("Stage1 train/test sizes:", X_train.shape, X_test.shape)

pipeline_stage1 = Pipeline([
    ('scaler', RobustScaler()),
    ('clf', RandomForestClassifier(n_estimators=200, class_weight='balanced', random_state=RANDOM_STATE, n_jobs=-1))
])

pipeline_stage1.fit(X_train, y_train)
print("Stage 1 trained.")

# Evaluate Stage 1
y_pred = pipeline_stage1.predict(X_test)
print("Stage 1 classification report (BENIGN vs ATTACK):")
print(classification_report(y_test, y_pred, target_names=['BENIGN','ATTACK']))
print("Confusion matrix:\n", confusion_matrix(y_test, y_pred))

# Save model
joblib.dump(pipeline_stage1, os.path.join(MODELS_DIR, "stage1_binary_pipeline_A.joblib"))